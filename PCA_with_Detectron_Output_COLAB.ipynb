{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tddqaRci1REJ"
   },
   "source": [
    "# Determining the biggest diagonal of masks from Detectron output on C3S-only dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmOSGkSRQOLi"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvMmP3dIRw4U"
   },
   "source": [
    "Common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sgMNM03rMofc"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORCZLvMGRziu"
   },
   "source": [
    "Install Detectron2 computer vision framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KV5hPx3jTBtm"
   },
   "outputs": [],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7-gGVFpTN5l"
   },
   "source": [
    "Import Detectron2 libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iH6FrM-TOJ8"
   },
   "outputs": [],
   "source": [
    "# DATA SET PREPARATION AND LOADING\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# VISUALIZATION\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# CONFIGURATION\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "# EVALUATION\n",
    "from detectron2.engine import DefaultPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKWKU8AAUobf"
   },
   "source": [
    "Clone repository with important files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HZJZQxOUobh"
   },
   "outputs": [],
   "source": [
    "!git clone 'https://github.com/la-zu-li/PCA-on-Semantic-Segmentation-with-Detectron2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLmvFHTyUobi"
   },
   "source": [
    "Get only important files from the repository\n",
    "\n",
    "> such as trained weights, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fB0zwQKFUobk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mv 'PCA-on-Semantic-Segmentation-with-Detectron2/pytorch' .\n",
    "!rm -r 'PCA-on-Semantic-Segmentation-with-Detectron2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6pfim_EMpKQ"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMb_08d7PMRE"
   },
   "source": [
    "Download from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZfpHUEgPRjN"
   },
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"sDHrdDWd5USqSBR0E7on\")\n",
    "project = rf.workspace(\"medusas\").project(\"alitas-tcc_h\")\n",
    "dataset = project.version(11).download(\"coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0UFconoPnqd"
   },
   "outputs": [],
   "source": [
    "DATA_SET_NAME = dataset.name.replace(\" \", \"-\")\n",
    "DATA_SET_LOCATION = dataset.location\n",
    "ANNOTATIONS_FILE_NAME = \"_annotations.coco.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dgRpgPiPea2"
   },
   "source": [
    "Dataset preprocessing (apply bilateral filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQ_zMffxUjwg"
   },
   "outputs": [],
   "source": [
    "def preprocess_coco_dataset(dataset_path, quiet=False):\n",
    "    BILATERAL_PARAMETERS = (2, 52, 84)\n",
    "\n",
    "    if not quiet:\n",
    "        print(f\"Preprocessing data on: {dataset_path}\")\n",
    "\n",
    "    img_filenames = os.listdir(dataset_path)\n",
    "    img_filenames.remove(\"_annotations.coco.json\")\n",
    "\n",
    "    for filename in img_filenames:\n",
    "        if not quiet:\n",
    "            print(f\"Applying Bilateral Filter on {filename}\")\n",
    "        try:\n",
    "            img = cv.imread(os.path.join(dataset_path, filename))\n",
    "            img = cv.bilateralFilter(img, *BILATERAL_PARAMETERS)\n",
    "            cv.imwrite(os.path.join(dataset_path, filename))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if not quiet:\n",
    "        print(f\"Data preprocessed successfully on {dataset_path}\")\n",
    "\n",
    "\n",
    "datasets_paths = [os.path.join(DATA_SET_LOCATION, 'train'),\n",
    "                 os.path.join(DATA_SET_LOCATION, 'test'),\n",
    "                 os.path.join(DATA_SET_LOCATION, 'valid'),]\n",
    "\n",
    "for dataset in datasets_paths:\n",
    "    preprocess_coco_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISZdVhfyVGf3"
   },
   "source": [
    "Prepare dataset for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdGWSOigUTsC"
   },
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n",
    "TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(DATA_SET_LOCATION, \"test\")\n",
    "TEST_DATA_SET_ANN_FILE_PATH = os.path.join(DATA_SET_LOCATION, \"test\", ANNOTATIONS_FILE_NAME)\n",
    "\n",
    "register_coco_instances(\n",
    "    name=TEST_DATA_SET_NAME,\n",
    "    metadata={},\n",
    "    json_file=TEST_DATA_SET_ANN_FILE_PATH,\n",
    "    image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9ghzXeXbn1u"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNKnZVQR1Ovq"
   },
   "source": [
    "### Configure network for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Die5FOLubgDA"
   },
   "source": [
    "Set output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jfs0l0owQSV1"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR_PATH = os.path.join(\n",
    "    \"output\",\n",
    "    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    ")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb37sKGrZc_0"
   },
   "source": [
    "Set specific configuration for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSMeyzW1MRop"
   },
   "outputs": [],
   "source": [
    "ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\"\n",
    "CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
    "cfg.DATASETS.TEST = (TEST_DATA_SET_NAME,)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ltSQ5ta02Np"
   },
   "source": [
    "### Load weights for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV1JWhMAysjX"
   },
   "source": [
    "Set pre-trained weights path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suGNezBvxO_i"
   },
   "outputs": [],
   "source": [
    "PRE_TRAINED_WEIGHTS_PATH = os.path.join(\n",
    "    \"pytorch/\",\n",
    "    DATA_SET_NAME,\n",
    "    ARCHITECTURE\n",
    ")\n",
    "\n",
    "outputs_all_instances = os.listdir(PRE_TRAINED_WEIGHTS_PATH)\n",
    "\n",
    "MOST_RECENT_PRE_TRAINED_WEIGHTS_PATH = os.path.join(\n",
    "    PRE_TRAINED_WEIGHTS_PATH,\n",
    "    outputs_all_instances[-1],\n",
    "    \"model_final.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_t1OFW_8zRNi"
   },
   "source": [
    "Load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thOHCzMIyv68"
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = MOST_RECENT_PRE_TRAINED_WEIGHTS_PATH\n",
    "print(f\"successfully loaded weights from {MOST_RECENT_PRE_TRAINED_WEIGHTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW0VX7JO1Dan"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w02En5zzUzp"
   },
   "source": [
    "Create predictor based on configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8Nb4n3FzCfW"
   },
   "outputs": [],
   "source": [
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE1QPKsc2ZRE"
   },
   "source": [
    "perform inference on test dataset with created predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2vkW0XXzwTl"
   },
   "outputs": [],
   "source": [
    "metadata = MetadataCatalog.get(TEST_DATA_SET_NAME)\n",
    "dataset_test = DatasetCatalog.get(TEST_DATA_SET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJQCC1syO7EY"
   },
   "outputs": [],
   "source": [
    "predicted_instances = {}\n",
    "\n",
    "for d in dataset_test:\n",
    "    img_file_path = d[\"file_name\"]\n",
    "    img = cv.imread(img_file_path)\n",
    "\n",
    "    outputs = predictor(img)\n",
    "    instances = outputs['instances']\n",
    "\n",
    "    predicted_instances[img_file_path] = instances\n",
    "\n",
    "    # visualizer = Visualizer(\n",
    "    #     img[:, :, ::-1],\n",
    "    #     metadata=metadata,\n",
    "    #     scale=0.8,\n",
    "    #     instance_mode=ColorMode.IMAGE_BW\n",
    "    # )\n",
    "    # out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    # cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRVenpunRcv3"
   },
   "source": [
    "## Measuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jelq36L75Zrn"
   },
   "source": [
    "Define measuring function to calculate biggest diagonal using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKBp0JWXQYCk"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def calc_longest_diagonal_pca(contour):\n",
    "\n",
    "    contour = np.squeeze(contour)\n",
    "\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(contour)\n",
    "\n",
    "    principal_component = pca.components_[0]\n",
    "    contour_pca = np.dot(contour, principal_component)\n",
    "\n",
    "    start_index = np.argmin(contour_pca)\n",
    "    end_index = np.argmax(contour_pca)\n",
    "\n",
    "    start, end = contour[start_index], contour[end_index]\n",
    "    start, end = tuple(start), tuple(end)\n",
    "    length = math.dist(start, end)\n",
    "\n",
    "    return start, end, length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE3rjfvR5qWj"
   },
   "source": [
    "Calculate longest diagonal with defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M65OG0085YXP"
   },
   "outputs": [],
   "source": [
    "diagonals = {}\n",
    "\n",
    "for (img_file_path, instances) in predicted_instances.items():\n",
    "    diagonals_of_img_masks = []\n",
    "\n",
    "    masks = instances.pred_masks.cpu()\n",
    "    masks_np = masks.numpy()\n",
    "    for mask in masks_np:\n",
    "        numerical_mask = mask.astype(np.uint8)\n",
    "        contours,_ = cv.findContours(numerical_mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "        contour = contours[0]\n",
    "        diagonal = calc_longest_diagonal_pca(contour)\n",
    "        diagonals_of_img_masks.append(diagonal)\n",
    "\n",
    "    diagonals[img_file_path] = diagonals_of_img_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4jN4rHcDIZo"
   },
   "source": [
    "Display measured diagonals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMs5OzYIrNfN"
   },
   "outputs": [],
   "source": [
    "IMAGES_SCALE_PX2NM = 0.8315\n",
    "\n",
    "def draw_diagonal_on_img(img, diag_start, diag_end, color=(0,0,255)):\n",
    "    cv.line(img, diag_start, diag_end, color)\n",
    "\n",
    "for (img_file_path, instances) in predicted_instances.items():\n",
    "\n",
    "    img = cv.imread(img_file_path)\n",
    "    visualizer = Visualizer(img[:, :, ::-1])\n",
    "    img_w_masks = visualizer.draw_instance_predictions(instances.to(\"cpu\"))\n",
    "    img_w_masks_np = img_w_masks.get_image()[:, :, ::-1]\n",
    "\n",
    "    diagonals_img = diagonals[img_file_path]\n",
    "\n",
    "    for start, end, length_pixels in diagonals_img:\n",
    "\n",
    "        img_w_masks_np_copy = np.array(img_w_masks_np)\n",
    "        draw_diagonal_on_img(img_w_masks_np_copy, start, end)\n",
    "        print(\"diagonal length (px): \", length_pixels)\n",
    "        length_nanometers = length_pixels * IMAGES_SCALE_PX2NM\n",
    "        print(\"diagonal length (nm): \", length_nanometers)\n",
    "\n",
    "        cv2_imshow(img_w_masks_np_copy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cmOSGkSRQOLi",
    "c6pfim_EMpKQ",
    "gNKnZVQR1Ovq",
    "-ltSQ5ta02Np"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
